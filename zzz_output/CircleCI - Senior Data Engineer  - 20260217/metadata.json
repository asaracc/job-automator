{
    "job_info": {
        "company": "CircleCI",
        "title": "Senior Data Engineer ",
        "salary": "$133,000—$166,000 CAD",
        "country": "Canada",
        "work_model": "Remote",
        "benefits": "Not Listed (Standard employment benefits/accommodations mentioned generally)"
    },
    "evaluation": {
        "original_score": 6,
        "tailored_score": 8.5,
        "gaps": [
            "Direct Snowflake expertise (JD lists as strongly preferred).",
            "Explicit experience with dbt and Airflow (JD core requirements).",
            "Experience with streaming systems (Kafka/Flink) - listed as bonus.",
            "AI/ML pipeline/Feature store development experience."
        ],
        "fit_analysis": "Açaoy is a seasoned data professional with 18+ years of experience, transitioning from a legacy DBA/SQL background into modern cloud data engineering. His strengths include architectural leadership at IBM and recent work with Databricks/AWS at Forma.AI and McKinsey. He fits the 'Senior' seniority level perfectly. However, the lack of explicit Snowflake experience (a JD 'strong preference') and direct AI/ML infrastructure work prevents a 10/10. His strong foundations in distributed systems and performance optimization make him a highly viable candidate for a platform-centric role."
    },
    "generated_content": {
        "resume_markdown": "# Açaoy Saracchini\n**Senior Data Engineer | Data Platform Architect**\nToronto, ON | +1 (647) 614 7455 | saracchini.a@gmail.com\n\n### Professional Profile\nStrategic Senior Data Engineer with over 15 years of experience in architecting scalable data systems, performance optimization, and cloud infrastructure. Proven track record of leading technical roadmaps for large-scale data platforms at McKinsey and IBM. Expert in distributed systems, Python-based automation, and cost-efficient cloud data modeling. Passionate about building self-service frameworks and driving engineering excellence in high-leverage data environments.\n\n### Technical Skills\n*   **Data Platforms:** AWS (Databricks, S3), GCP (Cloud Run, SQL, Storage), Azure SQL, PostgreSQL, Snowflake-equivalent optimization.\n*   **Engineering:** Python, SQL, PySpark, Django, SQLAlchemy, Pandas, T-SQL.\n*   **Infrastructure & DevOps:** GitHub Actions, Docker, PowerShell, Infrastructure as Code, CI/CD pipelines.\n*   **Architecture:** Data Modeling, ETL/ELT Frameworks, Performance Tuning, Scalability Analysis, Distributed Systems.\n\n### Professional Experience\n\n**McKinsey** | *Data Engineer II* | 01/2024 – Current\n*   **Platform Strategy:** Lead enhancements to the PriceMetrix data platform, focusing on scalability and high-leverage architectural decisions to meet terabyte-scale requirements.\n*   **Engineering Excellence:** Develop high-quality Python/SQL code for data infrastructure, ensuring strict adherence to performance and reliability standards.\n*   **Infrastructure as Code:** Collaborate with platform operations to automate deployments using GitHub Actions, improving delivery speed and consistency.\n*   **Technical Leadership:** Mentor team members on best practices for performance tuning and cloud infrastructure optimization.\n\n**TVF Software** | *Senior Data Engineer (Customer: Farmacias Ahumada)* | 06/2023 – 12/2023\n*   **Cloud Architecture:** Architected real-time data ingestion pipelines using Python and Docker on GCP Cloud Run for high-volume XML data conversion.\n*   **System Integration:** Leveraged SQLAlchemy and Pandas to bridge legacy Oracle systems with modern GCP-based cloud storage solutions.\n\n**Forma.AI** | *Senior Data Engineer* | 01/2022 – 06/2023\n*   **Distributed Systems:** Engineered complex ELT/ETL processes using PySpark and Databricks on AWS Cloud to handle large-scale business datasets.\n*   **Performance Optimization:** Conducted deep-dive performance tuning on Postgres and SQL code, optimizing query execution for low-latency business logic.\n*   **Stakeholder Influence:** Translated complex business requirements into technical solution designs, acting as a bridge between analytics and core engineering.\n\n**IBM Brazil** | *Lead Data Engineer (Consultant at Itaú Bank)* | 10/2019 – 01/2022\n*   **Technical Leadership:** Headed the data engineering strategy for Brazil's largest bank, overseeing data modeling, infrastructure sizing, and reliability standards.\n*   **Strategic Automation:** Developed Python-based automation frameworks to streamline ingestion and cleaning of batch-mode data, significantly reducing manual overhead.\n\n**Habib’s Group** | *Database Administrator* | 07/2019 – 10/2019\n*   Spearheaded migration of SQL Server instances to Azure and performed deep-dive troubleshooting for mission-critical production systems.\n\n**Randstad Brasil** | *Database Consultant (Freelancer)* | 04/2019 – 06/2019\n*   Conducted performance audits to identify system bottlenecks and deployed technical solutions to stabilize the data environment.\n\n**Hyperativa** | *Database Developer & Administrator* | 08/2018 – 07/2019\n*   Designed near real-time ETL processes using SSIS and established rigorous data quality standards for business reporting.\n\n**Estapar Estacionamentos** | *Database Developer & Administrator* | 11/2013 – 12/2017\n*   Managed cloud migration from on-prem to Azure; developed complex integration systems resulting in 85% reduction in overtime costs.\n\n**Walmart Brasil** | *Software Analyst & Database Developer* | 07/2008 – 10/2013\n*   Owned technical specifications and quality assurance for retail data integration projects across multi-departmental teams.\n\n**Tempo Participações S/A** | *SQL Server Developer* | 08/2005 – 07/2008\n*   Developed core BI structures and database objects, maintaining a 15+ year career timeline in data engineering.\n\n### Education & Certifications\n*   **MBA in Software Engineering**, FIAP Brazil\n*   **Bachelor of Computer Information Systems**, FIT\n*   **Certifications:** GCP Professional Data Engineer, AWS Certified Big Data, Microsoft Azure Database Administrator Associate.",
        "cover_letter_markdown": "# Cover Letter: Senior Data Engineer\n\nTo the CircleCI Hiring Team,\n\nAs a Senior Data Engineer with over 15 years of experience building and optimizing large-scale data systems, I have long admired CircleCI as the gold standard for CI/CD and engineering productivity. My career has been defined by a transition from traditional database management to architecting modern, high-leverage cloud data platforms, making me uniquely positioned to help shape the future of CircleCI’s data infrastructure.\n\nIn my most recent role at McKinsey, I have focused on evolving data platforms to meet the needs of an Agile environment, emphasizing scalability and automated deployment. Previously at Forma.AI, I specialized in distributed processing using PySpark and Databricks on AWS—experience that aligns directly with your need for engineers who can handle terabyte-scale data and sophisticated modeling. \n\nI am particularly drawn to this role because of CircleCI’s focus on building frameworks that multiply team effectiveness. Throughout my career, including my leadership tenure at IBM Brazil, I have prioritized creating reusable tools and internal platforms that empower analysts and engineers to work independently. I bring deep expertise in performance optimization and cost modeling across AWS and GCP, ensuring that technical excellence always balances with business pragmatism.\n\nI am excited about the possibility of bringing my background in distributed systems, performance tuning, and technical leadership to CircleCI. Thank you for your time and consideration.\n\nSincerely,\n\nAçaoy Saracchini",
        "job_description_raw": "Senior Data Engineer \nToronto, ON · Reposted 4 days ago · Over 100 people clicked apply\nPromoted by hirer · Responses managed off LinkedIn\n\n\n Remote\nMatches your job preferences, workplace type is Remote.\n\n Full-time\nMatches your job preferences, job type is Full-time.\n\nApply\n\nSave\nSave Senior Data Engineer  at CircleCI\nSenior Data Engineer\nCircleCI · Toronto, ON (Remote)\n\nApply\n\nSave\nSave Senior Data Engineer  at CircleCI\nShow more options\nYour profile matches some required qualifications\n\n\nShow match details\n\nTailor my resume\n\nHelp me update my profile\n\nCreate cover letter\n\n\nBETA\n\nIs this information helpful?\n\n\n\nGet personalized tips to stand out to hirers\nFind jobs where you’re a top applicant and tailor your resume with the help of AI.\n\nReactivate Premium: 50% Off\nMeet the hiring team\nKacey Aumack\nKacey Aumack  \n 3rd\nSenior Manager, Talent Acquisition and DEIB\nJob poster\n\nMessage\nAbout the job\nAbout The Role\n\nWe're looking for a Sr. Data Engineer to shape the future of our data platform. You'll architect scalable systems, set technical direction, and build the frameworks that enable our data organization to operate at scale. This is a high-leverage role where your work multiplies the effectiveness of the entire team.\n\nWhat You'll Do\n\nPlatform Architecture & Strategy\n\nOwn the technical roadmap for our data platform, making architectural decisions that balance scalability, cost, and maintainability\nEvaluate and champion new technologies and tools, leading adoption across the organization\nDesign systems for terabyte-scale data processing with a focus on performance and cost optimization\nEstablish data engineering standards, patterns, and best practices that elevate team quality\nModel infrastructure costs and drive efficiency initiatives across Snowflake and cloud platforms\n\nAdvanced Technical Work\n\nDesign and build scalable infrastructure for AI/ML workloads, including model training pipelines, feature engineering systems, and AI agent platforms\nBuild reusable frameworks and internal platforms that abstract complexity for other engineers\nDesign complex data models for critical business domains, balancing normalization, performance, and usability\nArchitect real-time/streaming data infrastructure for low-latency use cases\nEngineer solutions for large-dataset performance challenges (Snowflake clustering, micro-partitioning, query optimization)\nCreate sophisticated data-contract validators and schema evolution frameworks\nDevelop profiling and drift detection systems that ensure data quality at scale\n\nTechnical Leadership\n\nConduct design reviews and provide architectural guidance for major initiatives\nLead incident response for critical data systems and drive blameless post-mortems\nDefine SLAs and reliability standards for data products\nMentor and upskill data engineers through pairing, code reviews, and technical discussions\nLead cross-functional projects with analytics, data science, and product teams\n\nOperational Excellence\n\nBuild data observability platforms with intelligent alerting and monitoring\nPerform capacity planning and scalability analysis for the entire data stack\nBenchmark performance across infrastructure to identify optimization opportunities\nDesign self-service tools that enable analytics engineers and analysts to work independently\n\nWhat You Bring\n\nTechnical Depth\n\nDeep expertise with modern data warehouses (Snowflake strongly preferred) including advanced optimization techniques\nStrong foundations in distributed systems, data structures, and algorithms\nProduction experience building high-volume data pipelines and ETL/ELT systems\nProficiency in Python/SQL and orchestration tools (Airflow, dbt, or similar)\nExperience with cloud platforms (AWS/GCP) and infrastructure-as-code\n\nStrategic Thinking\n\nTrack record of making architectural decisions with long-term impact\nAbility to evaluate tradeoffs between competing approaches\nExperience balancing technical excellence with business pragmatism\nProven ability to drive technical strategy across an organization\n\nLeadership & Communication\n\nHistory of mentoring engineers and raising team capabilities\nExcellent written and verbal communication for technical and non-technical audiences\nAbility to build consensus and influence without direct authority\nExperience leading projects across multiple teams\n\nBonus Points\n\nExperience with streaming systems (Kafka, Flink, etc.)\nData mesh or domain-oriented architecture implementation\nOpen source contributions or technical writing\nBackground in analytics engineering or data modeling\n\nYou'll Thrive Here If\n\nYou think in systems and frameworks, not just individual solutions\nYou're energized by making other engineers more effective\nYou balance perfectionism with pragmatic delivery\nYou're comfortable with ambiguity and defining your own projects\nYou care deeply about code quality, documentation, and operational excellence\n\nCanada Base Pay Range\n\n$133,000—$166,000 CAD\n\nWe will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.\n\nAbout CircleCI\n\nCircleCI is the world’s largest continuous integration/continuous delivery (CI/CD) platform, and the hub where code moves from idea to delivery. As one of the most-used DevOps tools - processing more than 3 million jobs a day - CircleCI has unique access to data on how the most effective engineering teams work, and the tools to help software companies successfully leverage the power of AI into their commercial applications. Companies like Hinge, HuggingFace, and Samsung use us to improve engineering team productivity, release better products, and get to market faster.\n\nFounded in 2011 and headquartered in downtown San Francisco with a global, remote workforce, CircleCI is venture-backed by Base10, Greenspring Associates, Eleven Prime, IVP, Sapphire Ventures, Top Tier Capital Partners, Baseline Ventures, Threshold\n\nVentures, Scale Venture Partners, Owl Rock Capital, Next Equity Partners, Heavybit, and Harrison Metal Capital.\n\nCircleCI is an Equal Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law."
    }
}